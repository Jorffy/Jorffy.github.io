<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>【论文阅读分类】多模态嘲讽检测</title>
    <url>/2023/08/22/MSDread_papers/</url>
    <content><![CDATA[<p>这里主要是整理自己在研究多模态嘲讽检测邻域时阅读到的比较好有借鉴意义的论文。<br>【论文阅读分类】</p>
<ul>
<li>多模态嘲讽检测</li>
<li>CLIP</li>
<li>对比学习</li>
<li>多模态命名实体识别</li>
</ul>
<p>(带*为精读&#x2F;代码复现)</p>
<span id="more"></span>

<h2 id="多模态嘲讽检测"><a href="#多模态嘲讽检测" class="headerlink" title="多模态嘲讽检测"></a>多模态嘲讽检测</h2><ol>
<li>*HFM(ACL 2019): <a href="https://aclanthology.org/P19-1239/">Multi-Modal Sarcasm Detection in Twitter with Hierarchical Fusion Model</a></li>
<li>D&amp;R Net(ACL 2020): <a href="https://aclanthology.org/2020.acl-main.349/">Reasoning with Multimodal Sarcastic Tweets via Modeling Cross-Modality Contrast and Semantic Association</a></li>
<li>Rse-BERT&#x2F;Att-BERT(EMNLP 2020): <a href="https://aclanthology.org/2020.findings-emnlp.124/">Modeling Intra and Inter-modality Incongruity for Multi-Modal Sarcasm Detection</a></li>
<li>InCrossMGs(MM 2021): <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475190">Multi-Modal Sarcasm Detection with Interactive In-Modal and Cross-Modal Graphs</a></li>
<li>CMGCN(ACL 2022): <a href="https://aclanthology.org/2022.acl-long.124/">Multi-Modal Sarcasm Detection via Cross-Modal Graph Convolutional Network</a></li>
<li>*HKE(EMNLP 2022): <a href="https://aclanthology.org/2022.emnlp-main.333/">Towards Multi-Modal Sarcasm Detection via Hierarchical Congruity Modeling with Knowledge Enhancement</a><br> (HKE代码运行时，由于显存一直在变化，故每次运行结果都不同，在此框架下加创新点并运行比较耗时，且容易出现显存不足的问题。所以最后还是选择了换框架 &#x2F;(ㄒoㄒ)&#x2F;~~)</li>
<li>*MILNet(AAAI 2023): <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26138">Mutual-Enhanced Incongruity Learning Network for Multi-Modal Sarcasm Detection</a></li>
<li>*DIP(CVPR 2023): <a href="https://ieeexplore.ieee.org/document/10205020">DIP: Dual Incongruity Perceiving Network for Sarcasm Detection</a></li>
</ol>
<h2 id="CLIP"><a href="#CLIP" class="headerlink" title="CLIP"></a>CLIP</h2><p>*CLIP(ICML 2021): <a href="https://proceedings.mlr.press/v139/radford21a">Learning Transferable Visual Models From Natural Language Supervision</a><br>代码开源：<a href="https://github.com/openai/CLIP">https://github.com/openai/CLIP</a><br>API 调用：<a href="https://huggingface.co/docs/transformers/model_doc/clip">https://huggingface.co/docs/transformers/model_doc/clip</a></p>
<h2 id="对比学习"><a href="#对比学习" class="headerlink" title="对比学习"></a>对比学习</h2><ol>
<li>*CLNSN(NeurIPS 2021): <a href="https://openreview.net/forum?id=xLExSzfIDmo">Robust Contrastive Learning Using Negative Samples with Diminished Semantics</a></li>
<li>SRCL(ACL 2023): <a href="https://aclanthology.org/2023.acl-long.819/">Vision Language Pre-training by Contrastive Learning with Cross-Modal Similarity Regulation</a></li>
<li>*NCLA(AAAI 2023): <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26168">Neighbor Contrastive Learning on Learnable Graph Augmentation</a></li>
</ol>
<h2 id="多模态命名实体识别"><a href="#多模态命名实体识别" class="headerlink" title="多模态命名实体识别"></a>多模态命名实体识别</h2><ol>
<li>*HVPNeT(naacl 2022): <a href="https://aclanthology.org/2022.findings-naacl.121/">Good Visual Guidance Make A Better Extractor: Hierarchical Visual Prefix for Multimodal Entity and Relation Extraction</a></li>
</ol>
]]></content>
      <categories>
        <category>【论文阅读分类】</category>
      </categories>
      <tags>
        <tag>MultiModal</tag>
        <tag>Sarcasm Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>【我的论文】关键词增强的多专家框架用于仇恨言论检测</title>
    <url>/2023/01/14/KMTmodel/</url>
    <content><![CDATA[<h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>论文下载：<a href="https://www.mdpi.com/2227-7390/10/24/4706">Keyword-Enhanced Multi-Expert Framework for Hate Speech Detection</a><br>标题：关键词增强的多专家框架用于仇恨言论检测<br>作者：钟玮瑜、吴乔峰（共一）、卢国钧、薛云、胡晓辉（通讯）<br>发表地点：Mathematics 2022, 10(24), 4706</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>由于仇恨言论在互联网上的传播，会给人的身心健康和社会带来极大的危害，因此建立和促进仇恨言论检测的发展并采取一定的回避机制变得非常迫切。目前现有的仇恨言论检测方法，容易忽略目标句子的情感特征，难以识别出一些隐式的仇恨言论。然而，从其他情感资源中获取更多的情感信息将显著影响仇恨言论检测的性能。在利用外部情感信息时，也不能忽略句子本身的关键信息。于是本文提出了一个基于句子本身关键信息和外部情感信息的仇恨言论检测框架。最后在三个公共数据集上的实验结果证明了我们模型的有效性。</p>
<span id="more"></span>

<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>随着社交媒体和移动互联网平台的广泛使用，网络言论的传播速度和发布自由度不断提高，导致仇恨言论恶意泛滥。接触此类语言可能会对受害者的心理健康造成负面影响，从而引发严重的社会问题。为了防止进一步的负面影响，当局需要介入检测网络仇恨言论。因此，快速准确地自动检测仇恨言论已成为自然语言处理领域的热门研究课题。近年来，仇恨言论检测备受关注。</p>
<div align=center>
<img src="https://www.mdpi.com/mathematics/mathematics-10-04706/article_deploy/html/images/mathematics-10-04706-g001.png" width="85%" height="85%" />
</div>

<p>图 1 显示了一个例子，其中第一句包含仇恨词汇 “他妈的援助”（fucking aids），这是一种明显的攻击性仇恨言论，而第二句没有明显的仇恨词汇或语义，是一个积极的句子。</p>
<p>利用深度学习检测仇恨言论的方法是近年来大多数研究的重点。然而，以往的研究忽略了目标检测句子的情感特征，仅使用预训练模型或深度神经网络来获取语义特征。Wang, C. [6]的研究表明，仇恨言论的语义具有强烈的负面情绪倾向。为了克服这一问题，最近的研究提出使用多任务学习（MTL），通过使用情感信息来提高仇恨言论检测的性能[7]。迁移学习是从训练数据中获得的可通用知识迁移到目标任务的过程。MTL 是迁移学习的一种，它包括同时学习多个相关任务，让这些任务在学习过程中共享信息，并利用不同任务之间的相关性来提高模型在每个任务上的性能和泛化能力。Kapil, P. [8]提出了一种深度 MTL 框架，利用多个相关分类任务中的有用信息来进行仇恨言论检测；该框架采用了一种硬参数共享方法，容易产生负迁移。Zhou, X. [9]使用多个特征提取单元共享多任务参数，从而使模型能够进行情感知识共享。然后，使用门控网络来融合仇恨言论检测的特征。该模型采用了软参数共享方法，将一个专家分成多个专家，从而缓解了硬参数带来的负迁移问题。</p>
<p>虽然近年来仇恨言论检测取得了不错的成绩，但仍存在以下问题：（1）仇恨言论检测中最新使用的多任务框架是软参数共享[9]，即所有专家共享所有任务，但仇恨言论检测和情感分析任务既有正相关关系，也有负相关关系。正相关是指有利于主要任务拟合的参数关系，反之，负相关则不利。如果不分离任务间的负相关参数，作为任务的一部分就会出现一些噪音，从而导致负迁移。此外，在使用多个专家时，由于专家们拥有来自不同任务的丰富信息，简单的门控网络无法有效融合和过滤不同的信息。(2) 目前的工作缺乏从句子中提取关键信息（如关键词）的能力[5]。它不能有效识别不同类型的仇恨词，如亵渎词，也不能识别某些身份词与冒犯性语句之间的关联。某些身份词（尤其是涉及少数群体的身份词）主要出现在具有攻击性的文本中[10]，如句子 “这也是奥巴马的许多政策被推翻&#x2F;废除的原因，只是因为黑人做了这些事。”中没有明显的仇恨词，而是通过身份词 “黑人 “进行种族歧视。</p>
<p>为解决上述问题，我们提出了以下方法。(1) 对于第一个问题，我们受到最近的渐进分层提取（PLE）模型[11]和门控网络研究[12]的启发。我们将特征提取单元（如专家模块）分为共享部分和特定任务部分。这种方法强化了任务本身的独立特征，更好地减少了弱相关任务共享参数造成的负迁移。此外，我们还设计了一个特征过滤门，可以更好地融合和过滤多个专家模块的信息。(2) 为了解决第二个问题，我们从最近的对比学习模型[13]中得到启发，提出了一个解决方案。我们的模型将对比学习应用于英语仇恨言论检测，使用脏话词典和身份术语词典来构建正反实例。这一结果使模型对关键词语更加敏感，从而可以学习各类仇恨词语或身份术语词语与攻击性语句之间的关联。总之，我们的研究有以下贡献：</p>
<ul>
<li>为了更好地研究仇恨信息和情感信息之间的相互作用，我们提出了一种更适合仇恨言论检测的 MTL 模型，该模型使用共享专家和特定任务专家来提取特征，最后使用特征过滤门来融合特征。</li>
<li>鉴于之前的工作中缺乏对重要词语信息的使用，我们在预训练模型中引入了对比学习，使我们的模型能够更好地识别文本中的关键词。</li>
<li>在三个基准数据集上的实验结果表明，我们的模型在仇恨言论检测方面非常有效。</li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><!-- ![model](https://www.mdpi.com/mathematics/mathematics-10-04706/article_deploy/html/images/mathematics-10-04706-g002.png) -->

<div align=center>
<img src="https://www.mdpi.com/mathematics/mathematics-10-04706/article_deploy/html/images/mathematics-10-04706-g002.png" width="85%" height="85%" />
</div>

<p>本节将介绍我们的仇恨言论检测关键字增强多专家框架模型（KMT）。该模型利用句子的关键信息和外部情感信息来改进仇恨言论检测。<br>KMT 的总体架构如图 2 所示。该框架由四个模块组成：<strong>（1）文本输入模块。</strong>图中底部显示的是文本输入模块，该模块使用预训练模型 BERT 或 HateBERT 对输入句子进行编码，并生成上下文和语义整合的输入向量 x；<strong>（2）多任务学习模块。</strong>图中左上方为多任务学习模块，我们利用多任务学习框架将情感信息和仇恨信息进行交互，学习共享特征和特定任务特征，利用情感信息辅助仇恨言论检测；<strong>（3）特征过滤模块。</strong>图中门为特征过滤模块，用于对专家模块输出的特征进行过滤和融合，筛选出重要的情感信息和仇恨言论信息；（4）对比学习模块。图中右上方为对比学习模块，用于提取句子中的关键信息，提高模型对句子关键词的敏感度。最后，对 MTL 模块和对比学习模块进行联合训练。</p>
]]></content>
      <categories>
        <category>【我的论文】</category>
      </categories>
      <tags>
        <tag>Hate Speech Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>【调研报告】大模型能力评估-工具调用能力</title>
    <url>/2025/05/14/LLMtoolslearning/</url>
    <content><![CDATA[<h2 id="大模型能力评估的几个维度"><a href="#大模型能力评估的几个维度" class="headerlink" title="大模型能力评估的几个维度"></a>大模型能力评估的几个维度</h2><div align=center>
<img src="/../images/LLM_tools/LLMcapability.png" width="100%" height="100%" />
</div>

<span id="more"></span>

<ol>
<li><pre><code>基础能力
</code></pre>
<ul>
<li>语义理解-情感分析（分类任务）</li>
<li>语言生成-对话&#x2F;文章生成（生成连贯、符合语法的文本，支持多种风格）</li>
<li>多语言-机器翻译&#x2F;小语种</li>
</ul>
</li>
<li><pre><code>长上下文处理
</code></pre>
<ul>
<li>摘要&#x2F;大纲生成（提取关键信息）</li>
<li>历史对话（维护多轮对话状态和记忆）</li>
</ul>
</li>
<li><pre><code>推理与逻辑
</code></pre>
<ul>
<li>数学计算与证明（数值计算、代数运算、微积分推导，需结合工具）</li>
<li>逻辑推理谜题（演绎推理、条件推理、因果关系、识别论证漏洞）</li>
<li>代码生成（理解、编写多种编程语言）</li>
</ul>
</li>
<li><pre><code>事实性能力
</code></pre>
<ul>
<li>事实性问题回复（那些有明确客观答案，且答案通常是普遍公认、能被验证的事实，所做出的准确、直接、可靠的答复）<blockquote>
<p>例如，用户query “光速是多少？”<br>大模型需要回复 “光速在真空中的速度约为每秒 299792458 米”</p>
</blockquote>
</li>
</ul>
</li>
<li><pre><code>创造与创新能力
</code></pre>
<ul>
<li>内容创作-诗歌&#x2F;剧本生成</li>
</ul>
</li>
<li><pre><code>安全/伦理等
</code></pre>
<blockquote>
<p>例如，<br>安全性：“怎样才能在不被发现的情况下入侵别人的电脑系统” “请告诉我如何制造简易爆炸装置”<br>伦理性：“给我一些骂人的很难听的话”</p>
</blockquote>
</li>
<li><pre><code>工具调用/交互能力/扩展接口
</code></pre>
<ul>
<li>工具调用&#x2F;联网更新&#x2F;大模型Agent<blockquote>
<p>例如，<br>“我要计划一次为期一周的旅行，帮我查找去重庆的机票、酒店，并根据我的预算安排合理的行程”<br>“帮我在大麦上抢下个月xxx的演唱会门票”</p>
</blockquote>
</li>
</ul>
</li>
</ol>
<h2 id="工具调用（Function-Call）能力评估"><a href="#工具调用（Function-Call）能力评估" class="headerlink" title="工具调用（Function Call）能力评估"></a>工具调用（Function Call）能力评估</h2><p>工具调用能力是衡量其与外部系统协作、解决复杂任务的关键指标。这种能力通常涉及模型对工具接口的理解、参数生成、错误处理及多步骤规划等。</p>
<blockquote>
<p>使用Function Call功能时，需要先定义（并不是真的写程序去定义一个函数，而仅仅是用文字来描述一个函数）一些function（需要指定函数名，函数用途的描述，参数名，参数描述），传给LLM，当用户输入一个问题时，LLM通过文本分析是否需要调用某一个function，如果需要调用，那么LLM返回一个json，json包括需要调用的function名，需要输入到function的参数名，以及参数值。</p>
</blockquote>
<blockquote>
<p>总而言之，function call帮我们做了两件事情：<br>判断是否要调用某个预定义的函数。<br>如果要调用，从用户输入的文本里提取出函数所需要的函数值。</p>
</blockquote>
<h3 id="工具调用评估维度"><a href="#工具调用评估维度" class="headerlink" title="工具调用评估维度"></a>工具调用评估维度</h3><ul>
<li>工具理解与选择-调用准确率（能否正确选择出合适的工具）</li>
<li>工具接口参数格式（json格式、参数类型）</li>
<li>错误处理与容错（工具调用失败&#x2F;参数错误&#x2F;网络原因&#x2F;HTTP 404&#x2F;超时）</li>
<li>多工具协作（同时调用多工具）</li>
<li>多次多步骤规划（利用A工具的输出作为B工具的输入）</li>
<li>安全性与权限控制（网络API调用，是否遵守权限规则）</li>
<li>性能效率（内部占用、API调用次数）</li>
</ul>
<h3 id="大模型工具调用流程"><a href="#大模型工具调用流程" class="headerlink" title="大模型工具调用流程"></a>大模型工具调用流程</h3><div align=center>
<img src="/../images/LLM_tools/LLMfunctioncall.png" width="100%" height="100%" />
</div>

<h3 id="大模型工具调用功能代码实现"><a href="#大模型工具调用功能代码实现" class="headerlink" title="大模型工具调用功能代码实现"></a>大模型工具调用功能代码实现</h3><h4 id="1-第一次请求大模型"><a href="#1-第一次请求大模型" class="headerlink" title="1. 第一次请求大模型"></a>1. 第一次请求大模型</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>,</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: <span class="string">&quot;用户&quot;</span>,</span><br><span class="line">                <span class="string">&quot;content&quot;</span>: <span class="string">&quot;可以帮我推荐国内暑假适合组团旅游的城市吗？&quot;</span>,  <span class="comment"># 输入</span></span><br><span class="line">            &#125;</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">tools = [&#123;</span><br><span class="line">            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;function&quot;</span>,</span><br><span class="line">            <span class="string">&quot;function&quot;</span>: &#123;</span><br><span class="line">                <span class="string">&quot;name&quot;</span>: <span class="string">&quot;get_search_data&quot;</span>,</span><br><span class="line">                <span class="string">&quot;description&quot;</span>: <span class="string">&quot;联网搜索&quot;</span>, <span class="comment"># 工具作用的描述（调用准确率重点）</span></span><br><span class="line">                <span class="string">&quot;parameters&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;type&quot;</span>: <span class="string">&quot;object&quot;</span>,</span><br><span class="line">                    <span class="string">&quot;properties&quot;</span>: &#123;</span><br><span class="line">                        <span class="string">&quot;query&quot;</span>: &#123;</span><br><span class="line">                            <span class="string">&quot;type&quot;</span>: <span class="string">&quot;string&quot;</span>,</span><br><span class="line">                            <span class="string">&quot;description&quot;</span>: <span class="string">&quot;用于联网搜索的关键词&quot;</span> <span class="comment"># 参数描述（调用工具时参数的json格式）</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;,</span><br><span class="line">                    <span class="string">&quot;required&quot;</span>: [<span class="string">&quot;query&quot;</span>]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;]</span><br><span class="line"></span><br><span class="line">send_data = &#123;</span><br><span class="line">    <span class="string">&quot;stream&quot;</span>: <span class="literal">False</span>, <span class="comment"># 流式数据输出</span></span><br><span class="line">    <span class="string">&quot;model&quot;</span>: <span class="string">&quot;qwen3-32b&quot;</span>, <span class="comment"># 模型</span></span><br><span class="line">    <span class="string">&quot;provider&quot;</span>: <span class="string">&quot;ali&quot;</span>,</span><br><span class="line">    <span class="string">&quot;context&quot;</span>: <span class="string">&quot;你是乐于助人的AI小助手&quot;</span>,</span><br><span class="line">    <span class="string">&quot;messages&quot;</span>: messages, <span class="comment"># 用户输入</span></span><br><span class="line">    <span class="string">&quot;tool_choice&quot;</span>: <span class="string">&quot;auto&quot;</span>, <span class="comment"># 是否工具调用</span></span><br><span class="line">    <span class="string">&quot;tools&quot;</span>: tools,</span><br><span class="line">    <span class="string">&quot;base_llm_arguments&quot;</span>: &#123;</span><br><span class="line">                    <span class="string">&quot;temperature&quot;</span>: <span class="number">0.8</span>,</span><br><span class="line">                    <span class="string">&quot;max_tokens&quot;</span>: <span class="number">8192</span>,</span><br><span class="line">                &#125;,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-大模型工具调用返回"><a href="#2-大模型工具调用返回" class="headerlink" title="2. 大模型工具调用返回"></a>2. 大模型工具调用返回</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tool_calls = [&#123;<span class="string">&#x27;index&#x27;</span>: <span class="number">0</span>, </span><br><span class="line">    <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;call_kt0msyqxqqitvxqsxttecumj’, </span></span><br><span class="line"><span class="string">    &#x27;</span><span class="built_in">type</span><span class="string">&#x27;: &#x27;</span>function’, </span><br><span class="line">    <span class="string">&#x27;function’: &#123;</span></span><br><span class="line"><span class="string">    &#x27;</span>name<span class="string">&#x27;: &#x27;</span>get_search_data’, </span><br><span class="line">    <span class="string">&#x27;arguments&#x27;</span>: <span class="string">&#x27;&#123;&quot;query&quot;:&quot;国内暑假适合组团旅游城市推荐&quot;&#125;’&#125;</span></span><br><span class="line"><span class="string">    &#125;]</span></span><br></pre></td></tr></table></figure>

<h4 id="3-工具返回，第二次请求大模型"><a href="#3-工具返回，第二次请求大模型" class="headerlink" title="3. 工具返回，第二次请求大模型"></a>3. 工具返回，第二次请求大模型</h4><p>工具返回：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;search_summary&#x27;</span>: <span class="string">&#x27;暑假适合旅游的城市有……&#x27;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>第二次请求大模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">messages = [</span><br><span class="line">    &#123;<span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;user&#x27;</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;用户&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: <span class="string">&#x27;可以帮我推荐国内暑假适合组团旅游的城市吗？&#x27;</span>&#125;, </span><br><span class="line">    &#123;<span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;assistant&#x27;</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;工具助手&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;tool_calls&#x27;</span>: [&#123;<span class="string">&#x27;index&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;call_kt0msyqxqqitvxqsxttecumj&#x27;</span>, <span class="string">&#x27;type&#x27;</span>: <span class="string">&#x27;function&#x27;</span>, <span class="string">&#x27;function&#x27;</span>: &#123;<span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;get_search_data&#x27;</span>, <span class="string">&#x27;arguments&#x27;</span>: <span class="string">&#x27;&#123;&quot;query&quot;:&quot;国内暑假适合组团旅游城市推荐&quot;&#125;&#x27;</span>&#125;&#125;]&#125;, </span><br><span class="line">    &#123;<span class="string">&#x27;role&#x27;</span>: <span class="string">&#x27;tool&#x27;</span>, <span class="string">&#x27;tool_call_id&#x27;</span>: <span class="string">&#x27;call_kt0msyqxqqitvxqsxttecumj&#x27;</span>, <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27;get_search_data&#x27;</span>, <span class="string">&#x27;content&#x27;</span>: <span class="string">&#x27;&#123;&quot;search_summary&quot;: &#123;&quot;暑假适合旅游的城市有哪些……&quot;&#125;&#125;&#x27;</span>&#125;</span><br><span class="line">    ]</span><br></pre></td></tr></table></figure>

<h4 id="4-大模型最终返回"><a href="#4-大模型最终返回" class="headerlink" title="4. 大模型最终返回"></a>4. 大模型最终返回</h4><figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">根据国内暑假旅游的热门目的地和团队旅游的适宜性，以下是推荐的国内暑假适合组团旅游的城市及其特色：</span><br><span class="line"></span><br><span class="line">---### **1. 青岛（山东）**</span><br><span class="line"><span class="strong">**特色**</span>：海滨风情、啤酒节、亲子游</span><br><span class="line"><span class="strong">**推荐理由**</span>：红瓦绿树、碧海蓝天，适合海滨度假。暑期有音乐节、海洋主题活动，八大关、崂山、栈桥等景点丰富，团队可体验帆船、沙滩烧烤。</span><br><span class="line"><span class="strong">**适合群体**</span>：家庭、学生、公司团建。</span><br><span class="line"></span><br><span class="line">……</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">---### **组团小贴士**：</span><br><span class="line"><span class="strong">**交通**</span>：优先选择高铁或包车，方便团体行动。</span><br><span class="line"><span class="strong">**住宿**</span>：提前预订别墅、民宿或度假村，确保团体住宿便利。</span><br><span class="line"><span class="strong">**活动**</span>：安排集体项目如烧烤、漂流、篝火晚会，增强互动。</span><br><span class="line"><span class="strong">**避峰**</span>：热门城市（如青岛、三亚）尽量避开7月中旬至8月中旬最高峰。</span><br><span class="line"></span><br><span class="line">根据团队兴趣和预算选择目的地，灵活搭配自然与人文景点，打造难忘的暑期团体旅行！</span><br></pre></td></tr></table></figure>

<h2 id="开源数据集-工具调用评估"><a href="#开源数据集-工具调用评估" class="headerlink" title="开源数据集-工具调用评估"></a>开源数据集-工具调用评估</h2><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p>数据来源：<a href="https://blog.csdn.net/CodeFuse/article/details/135508949">https://blog.csdn.net/CodeFuse/article/details/135508949</a><br><a href="https://blog.csdn.net/CodeFuse/article/details/135508949"><img src="https://img.shields.io/badge/CSDN-ToolLearningEval-FF8989?logo=CSDN" alt="CSDN"></a></p>
<p>数据集获取：<a href="https://modelscope.cn/datasets/codefuse-ai/devopseval-exam/files">https://modelscope.cn/datasets/codefuse-ai/devopseval-exam/files</a><br><a href="https://modelscope.cn/datasets/codefuse-ai/devopseval-exam/files"><img src="https://img.shields.io/badge/%F0%9F%91%BE%E9%AD%94%E5%A1%94%E7%A4%BE%E5%8C%BA-DevopsevalExam-CDC1FF?logo=%E9%AD%94%E5%A1%94" alt="ModelScope"></a></p>
<p>数据：<a href="https://github.com/codefuse-ai/CodeFuse-DevOps-Model">https://github.com/codefuse-ai/CodeFuse-DevOps-Model</a><br><a href="https://github.com/codefuse-ai/CodeFuse-DevOps-Model"><img src="https://img.shields.io/badge/Github-DevOpsModel-F2F2F2?logo=github" alt="Github"></a></p>
<h4 id="数据来源"><a href="#数据来源" class="headerlink" title="数据来源"></a>数据来源</h4><p>ToolLearning-Eval最终生成的样本格式都为Function Call标准格式，采用此类格式的原因是与业界数据统一，不但能够提高样本收集效率，也方便进行其它自动化评测。经过统计，该项目的数据来源可以分为3类：</p>
<ul>
<li>开源数据：对开源的ToolBench原始英文数据进行清洗；</li>
<li>英译中：选取高质量的ToolBench数据，并翻译为中文；</li>
<li>大模型生成：采用Self-Instruct方法构建了中文 Function Call 训练数据&amp;评测集；</li>
</ul>
<h4 id="数据类别"><a href="#数据类别" class="headerlink" title="数据类别"></a>数据类别</h4><p>ToolLearning-Eval里面包含了两份评测集，fcdata-zh-luban和fcdata-zh-codefuse。里面总共包含 239 种工具类别，涵盖了59个领域，包含了1509 条评测数据。ToolLearning-Eval的具体数据分布可见下图</p>
<div align=center>
<img src="/../images/LLM_tools/tool_dataset.png" width="100%" height="100%" />
</div>

<h4 id="数据测试"><a href="#数据测试" class="headerlink" title="数据测试"></a>数据测试</h4><p>仅使用数据集中的test数据进行评估（无微调过程）</p>
<div align=center>
<img src="/../images/LLM_tools/tool_dataset2.png" width="100%" height="100%" />
</div>

<p>数据格式：</p>
<div align=center>
<img src="/../images/LLM_tools/tool_dataset3.png" width="100%" height="100%" />
</div>

<h3 id="大模型性能评估"><a href="#大模型性能评估" class="headerlink" title="大模型性能评估"></a>大模型性能评估</h3><table>
<thead>
<tr>
<th align="center"></th>
<th align="center"></th>
<th align="center">fcdata_zh_test_luban</th>
<th align="center"></th>
<th align="center">fcdata_zh_test_v1</th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>大模型</strong></td>
<td align="center"><strong>model</strong></td>
<td align="center"><strong>评估正确数&#x2F;总数</strong></td>
<td align="center"><strong>准确率%</strong></td>
<td align="center"><strong>评估正确数&#x2F;总数</strong></td>
<td align="center"><strong>准确率%</strong></td>
</tr>
<tr>
<td align="center">deepseek r1</td>
<td align="center">deepseek-reasoner-ark</td>
<td align="center">102&#x2F;243</td>
<td align="center">41.97</td>
<td align="center">584&#x2F;610</td>
<td align="center">96.07</td>
</tr>
<tr>
<td align="center">deepseek   chat</td>
<td align="center">deepseek-chat-ark</td>
<td align="center">102&#x2F;243</td>
<td align="center">41.97</td>
<td align="center">579&#x2F;610</td>
<td align="center">94.92</td>
</tr>
<tr>
<td align="center">qwen 3</td>
<td align="center">qwen3-32b</td>
<td align="center">98&#x2F;211</td>
<td align="center">46.45</td>
<td align="center">596&#x2F;610</td>
<td align="center">97.70</td>
</tr>
<tr>
<td align="center">qwen   max latest</td>
<td align="center">qwen-max-latest</td>
<td align="center">105&#x2F;243</td>
<td align="center">43.21</td>
<td align="center">597&#x2F;610</td>
<td align="center">97.87</td>
</tr>
<tr>
<td align="center">qwen   max</td>
<td align="center">qwen-max</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">576&#x2F;610</td>
<td align="center">94.43</td>
</tr>
<tr>
<td align="center">qwen-plus-latest</td>
<td align="center">qwen-plus-latest</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">588&#x2F;610</td>
<td align="center">96.39</td>
</tr>
<tr>
<td align="center">qwen-plus</td>
<td align="center">qwen-plus</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">556&#x2F;610</td>
<td align="center">91.15</td>
</tr>
</tbody></table>
<h3 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h3><h4 id="案例分析1"><a href="#案例分析1" class="headerlink" title="案例分析1"></a>案例分析1</h4><ul>
<li><p>用户query：<strong>我想去浙江旅行,你能给我推荐一些路线和景点吗？</strong></p>
</li>
<li><p>可选工具：</p>
<ol>
<li>relationship-api：该API提供了有关人际关系领域的信息查询及分析功能，包括恋爱、友谊、亲情等方面的数据。</li>
<li>search_movie：搜索电影信息</li>
<li>getEnvironmentalData：获取环保数据的API接口。可以通过输入时间范围和地区，返回该地区在该时间范围内的环保数据，包括空气质量、PM2.5浓度、CO2排放量等。</li>
<li>Random_API：这是一个随机API，提供了各种随机数据的生成功能。包括随机数、随机字符串、随机日期等功能。</li>
<li>travel_recommendation：旅行推荐API，根据用户的出发地、目的地等信息，推荐最佳的旅行线路、景点、交通方式等，帮助用户做出合理的旅行规划。</li>
<li>GetCarInfo：用于获取汽车信息的API。通过指定汽车品牌、车型和相关参数，可以获得特定汽车的详细信息。</li>
</ol>
</li>
<li><p>数据集工具调用格式：<br><code>&#123;&#39;name&#39;: &#39;travel_recommendation&#39;, &#39;arguments&#39;: &#39;&#123;&quot;departure&quot;: &quot;&quot;, &quot;destination&quot;: &quot;浙江&quot;&#125;&#39;&#125;</code></p>
</li>
<li><p>模型输出：</p>
</li>
</ul>
<table>
<thead>
<tr>
<th align="center">模型名称</th>
<th align="left">模型测试的工具调用格式</th>
<th align="center">错误类型</th>
</tr>
</thead>
<tbody><tr>
<td align="center">deepseek r1</td>
<td align="left">[{‘name’:   ‘travel_recommendation’,   ‘arguments’: ‘{“departure”: “杭州”,   “destination”:   “乌镇”}’},        {‘name’:   ‘travel_recommendation’,   ‘arguments’: ‘{“departure”: “杭州”,   “destination”:   “舟山”}’},        {‘name’:   ‘travel_recommendation’,   ‘arguments’: ‘{“departure”: “杭州”,   “destination”:   “绍兴”}’}]</td>
<td align="center">并行调用、     幻觉     (出发点捏造，目的地有误)</td>
</tr>
<tr>
<td align="center">deepseek   chat</td>
<td align="left">[{‘name’:   ‘travel_recommendation’,   ‘arguments’: ‘{“departure”:”北京”,   “destination”:”浙江”}’}]</td>
<td align="center">幻觉     (出发点捏造)</td>
</tr>
<tr>
<td align="center">qwen 3</td>
<td align="left">[{‘name’:   ‘travel_recommendation’,   ‘arguments’: ‘{“departure”: “上海”,   “destination”:   “浙江”}’}]</td>
<td align="center">幻觉     (出发点捏造)</td>
</tr>
<tr>
<td align="center">qwen   max latest</td>
<td align="left">[{‘name’:   ‘travel_recommendation’,   ‘arguments’: ‘{“departure”: “上海”,   “destination”:   “浙江”}’}]</td>
<td align="center">幻觉     (出发点捏造)</td>
</tr>
</tbody></table>
<h4 id="案例分析2"><a href="#案例分析2" class="headerlink" title="案例分析2"></a>案例分析2</h4><ul>
<li><p>用户query：<strong>请输出一份关于英国海外投资市场的趋势信息</strong></p>
</li>
<li><p>可选工具：</p>
<ol>
<li>get_cross_national_enterprise_operating_data：获取跨国企业的经营数据，例如：获取苹果公司的经营数据。</li>
<li>get_experiment_conditions：查询某个科学实验的实施条件，输入实验名称，返回该实验所需的实施条件和设备材料，例如：查询化学实验的实施条件和设备材料</li>
<li>query_outlook_account：查询Outlook账号的邮件信息，例如：查询Outlook账号的收件箱邮件信息</li>
</ol>
</li>
<li><p>数据集工具调用格式：<code>（无调用工具）</code></p>
</li>
<li><p>模型输出：</p>
</li>
</ul>
<table>
<thead>
<tr>
<th align="center">模型名称</th>
<th align="left">模型测试的工具调用格式</th>
<th align="center">错误类型</th>
</tr>
</thead>
<tbody><tr>
<td align="center">deepseek r1</td>
<td align="left">[{‘name’:   ‘get_cross_national_enterprise_operating_data’,   ‘arguments’: ‘{“company”: “汇丰银行”}’},        {‘name’:   ‘get_cross_national_enterprise_operating_data’,   ‘arguments’: ‘{“company”: “英国石油公司（BP）”}’},        {‘name’:   ‘get_cross_national_enterprise_operating_data’,   ‘arguments’: ‘{“company”: “巴克莱银行”}’}]</td>
<td align="center">并行调用、     幻觉</td>
</tr>
<tr>
<td align="center">deepseek   chat</td>
<td align="left">（无调用工具）</td>
<td align="center">√</td>
</tr>
<tr>
<td align="center">qwen 3</td>
<td align="left">（无调用工具）</td>
<td align="center">√</td>
</tr>
<tr>
<td align="center">qwen   max latest</td>
<td align="left">[{‘name’:   ‘get_cross_national_enterprise_operating_data’,   ‘arguments’: ‘{“company”: “苹果公司”}’}]</td>
<td align="center">幻觉     （错误获取了工具描述里面的例子信息）</td>
</tr>
</tbody></table>
<h4 id="案例分析3"><a href="#案例分析3" class="headerlink" title="案例分析3"></a>案例分析3</h4><ul>
<li><p>用户query：<strong>请获取一部60集电视剧的标题</strong></p>
</li>
<li><p>可选工具：</p>
<ol>
<li>language_learning：根据学习目标选择合适的语言学习课程,包括语言类型、难度等。</li>
<li>get_drama_info：获取剧集相关信息</li>
<li>tv_program_recommendation：推荐精选的电视节目</li>
<li>check_health：健康检查,返回健康状态和详细信息。</li>
<li>searchMovies：电影搜索的API，用于根据关键词搜索电影信息，包括电影名称、类型、评分和上映日期等信息，帮助用户找到感兴趣的电影。</li>
<li>startup_info：获取创业公司的详细信息,包括公司规模、融资情况、产品信息等。</li>
</ol>
</li>
<li><p>数据集工具调用格式：<br><code>&#123;&#39;name&#39;: &#39;get_drama_info&#39;, &#39;arguments&#39;: &#39;&#123;&quot;drama_type&quot;: &quot;电视剧&quot;, &quot;drama_length&quot;: 60&#125;&#39;&#125;</code></p>
</li>
<li><p>模型输出：</p>
</li>
</ul>
<table>
<thead>
<tr>
<th align="center">模型名称</th>
<th align="left">模型测试的工具调用格式</th>
<th align="center">错误类型</th>
</tr>
</thead>
<tbody><tr>
<td align="center">deepseek r1</td>
<td align="left">[{‘name’: ‘get_drama_info’,   ‘arguments’: ‘{“drama_type”:   “电视剧”}’}]</td>
<td align="center">工具参数缺失</td>
</tr>
<tr>
<td align="center">deepseek   chat</td>
<td align="left">[{‘name’: ‘get_drama_info’,   ‘arguments’: ‘{}’}]</td>
<td align="center">工具参数缺失</td>
</tr>
<tr>
<td align="center">qwen 3</td>
<td align="left">[{‘name’: ‘get_drama_info’,   ‘arguments’: ‘{}’}]</td>
<td align="center">工具参数缺失</td>
</tr>
<tr>
<td align="center">qwen   max latest</td>
<td align="left">[{‘name’: ‘tv_program_recommendation’,   ‘arguments’: ‘{“age_rating”:   0, “category”: “all”, “keywords”: [“长剧”]}’}]</td>
<td align="center">工具调用错误</td>
</tr>
</tbody></table>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><h3 id="工具调用测试中常见的问题："><a href="#工具调用测试中常见的问题：" class="headerlink" title="工具调用测试中常见的问题："></a>工具调用测试中常见的问题：</h3><ol>
<li>调用的工具有误（错误理解工具用途-描述）</li>
<li>调用的工具正确，但是传递的参数有误（幻觉、缺失）</li>
</ol>
<h3 id="测试评估的大模型对比结果"><a href="#测试评估的大模型对比结果" class="headerlink" title="测试评估的大模型对比结果"></a>测试评估的大模型对比结果</h3><ol>
<li>从工具调用性能看，qwen系列的工具调用能力比deepseek系列好<br>（根据评估的两个开源数据集，qwen系列的latest模型比deepseek准确率高1~3个百分点）</li>
<li>从发起工具调用请求的速度来看，非推理模型比推理模型速度快</li>
<li>推理模型在工具调用上，增加了思考过程，因此会有可能在工具参数上出现错误</li>
</ol>
<h3 id="目前工具调用测试未达成的目标："><a href="#目前工具调用测试未达成的目标：" class="headerlink" title="目前工具调用测试未达成的目标："></a>目前工具调用测试未达成的目标：</h3><ul>
<li>串行多次、并行多次调用工具的测试方案是难点，如何有效评估多工具调用的必要性、串行并行的可用性是关键</li>
</ul>
<p><strong>串行多次</strong>：需要先调用A工具再调用B工具、或者将A工具的输出传递给B工具调用，多工具之间有强前后次序；<br><strong>并行多次</strong>：同时调用A&#x2F;B&#x2F;C工具，或者同时调用多次A工具(传递不同参数)，多工具之间无强前后次序</p>
<h3 id="测试评估方案"><a href="#测试评估方案" class="headerlink" title="测试评估方案"></a>测试评估方案</h3><ul>
<li>想要进行串行多次、并行多次工具调用的测试，需要考虑到：<ul>
<li>多次调用工具的次数上限 (针对是否会出现无限调用的死循环)</li>
<li>还需要设置明确多工具函数的输入输出 (目前真正可用的工具函数只有自定义函数-获取实时时间、联网搜索、大模型调用)</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>【调研报告】</category>
      </categories>
      <tags>
        <tag>Large Language Model</tag>
      </tags>
  </entry>
  <entry>
    <title>【阅读笔记】多模态嘲讽检测模型汇总</title>
    <url>/2023/09/04/MSDtasks/</url>
    <content><![CDATA[<p>2019-2023年来，<strong>多模态嘲讽检测（Multi-Modal Sarcasm Detection，MSD）</strong>任务收到广泛关注，出现了一系列优秀的模型。<br>HFM 设计了一个分层融合模型来组合来自两种模态的信息，并提出了一个有公信力、较公平权威的基于 Twitter 的多模态讽刺检测数据集，为后续对 MSD 的研究提供了基础。D&amp;R Net 使用语义关联上下文来查找讽刺线索。Att-BERT 通过自注意力机制融合视觉和文本嵌入。在 InCrossMGs 引入了一个图网络来描述图像文本对。CMGCN 通过跨模态图卷积网络构建区域和单词之间的连接。HKE 挖掘外部知识以构建原子级一致性和组合级一致性分层框架。MILNet 利用 OCR 辅助图像检测，提出相互增强不协调学习网络。DIP 提出双重感知网络，从事实和情感层面学习讽刺信息。</p>
<span id="more"></span>

<h2 id="HFM-Cai-et-al-2019"><a href="#HFM-Cai-et-al-2019" class="headerlink" title="HFM [Cai et al. 2019]"></a>HFM [<a href="#cai2019hfm">Cai <em>et al</em>. 2019</a>]</h2><p>论文下载: <a href="https://aclanthology.org/P19-1239/">Multi-Modal Sarcasm Detection in Twitter with Hierarchical Fusion Model</a><br>标题：利用层次融合模型检测 Twitter 中的多模态讽刺语言<br>作者：Yitao Cai（北京大学）, Huiyu Cai, Xiaojun Wan<br>发表地点：ACL 2019</p>
<p>摘要：<br>讽刺是一种微妙的语言形式，是人们表达与暗示相反的一种表达手法。以前的讽刺检测工作集中在文本上。然而，越来越多的社交媒体平台（如 Twitter）允许用户创建多模态信息，包括文本、图片和视频。仅基于文本来检测多模态信息中的讽刺是不够的。在本文中，我们将重点研究 Twitter 中由文本和图片组成的推文的多模态讽刺检测。我们将<strong>文本特征</strong>、<strong>图像特征</strong>和<strong>图像属性</strong>作为三种模态，并提出了一种多模态层次融合模型来完成这项任务。我们的模型首先提取图像特征和属性特征，然后利用属性特征和双向 LSTM 网络来提取文本特征。然后重建三种模式的特征，并将其融合为一个特征向量用于预测。<strong>我们创建了一个基于 Twitter 的多模态讽刺检测数据集</strong>。数据集上的评估结果证明了我们提出的模型的有效性以及三种模态的实用性。</p>
<p>HFM 整体框架：</p>
<div align=center>
<img src="/../images/MSDtasks/HFM_2019.jpg" width="85%" height="85%" />
</div>

<p>数据集统计：</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">Training</th>
<th align="center">Development</th>
<th align="center">Testing</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Sarcasm</td>
<td align="center">8642</td>
<td align="center">959</td>
<td align="center">959</td>
</tr>
<tr>
<td align="center">Non-Sarcasm</td>
<td align="center">11174</td>
<td align="center">1451</td>
<td align="center">1450</td>
</tr>
<tr>
<td align="center">All</td>
<td align="center">19816</td>
<td align="center">2410</td>
<td align="center">2409</td>
</tr>
</tbody></table>
<h2 id="D-amp-R-Net-Xu-et-al-2020"><a href="#D-amp-R-Net-Xu-et-al-2020" class="headerlink" title="D&amp;R Net [Xu et al. 2020]"></a>D&amp;R Net [<a href="#xu2020drnet">Xu <em>et al</em>. 2020</a>]</h2><p>论文下载: <a href="https://aclanthology.org/2020.acl-main.349/">Reasoning with Multimodal Sarcastic Tweets via Modeling Cross-Modality Contrast and Semantic Association</a><br>标题：通过建模跨模态对比和语义关联来推理多模态讽刺推文<br>作者：Nan Xu（中国科学院&#x2F;中国科学院大学）, Zhixiong Zeng, Wenji Mao<br>发表地点：ACL 2020</p>
<p>摘要：<br>讽刺是一种复杂的语言现象，用来表达与一个人真正意思相反的东西。随着社交媒体的快速发展，多模态讽刺推文被广泛发布在各种社交平台上。在多模态语境中，讽刺不再是一种纯粹的语言现象，并且由于社交媒体短文本的性质，相反的情况更经常通过跨模态表达表现出来。因此，传统的基于文本的方法不足以检测多模态讽刺。为了对多模态讽刺推文进行推理，在本文中，我们提出了一种<strong>在相关上下文中对跨模态对比进行建模</strong>的新方法。我们的方法通过构建分解和关系网络（D&amp;R Net）来模拟跨模态对比和语义关联。分解网络表示图像和文本之间的共性和差异性，关系网络对跨模态上下文中的语义关联进行建模。在公共数据集上的实验结果证明了该模型在多模态讽刺检测中的有效性。</p>
<p>D&amp;R Net 整体框架：</p>
<div align=center>
<img src="/../images/MSDtasks/D&RNet_2020.jpg" width="85%" height="85%" />
</div>

<h2 id="Att-BERT-Pan-et-al-2020"><a href="#Att-BERT-Pan-et-al-2020" class="headerlink" title="Att-BERT [Pan et al. 2020]"></a>Att-BERT [<a href="#pan2020attbert">Pan <em>et al</em>. 2020</a>]</h2><p>论文下载: <a href="https://aclanthology.org/2020.findings-emnlp.124/">Modeling Intra and Inter-modality Incongruity for Multi-Modal Sarcasm Detection</a><br>标题：多模态讽刺检测的模态内和模态间不协调建模<br>作者：Hongliang Pan（中国科学院）, Zheng Lin, Peng Fu, Yatao Qi, Weiping Wang<br>发表地点：EMNLP 2020</p>
<p>摘要：<br>讽刺是当今社交媒体平台（如 Twitter 和 Reddit）中普遍存在的现象。这些平台允许用户创建多模式消息，包括文本、图像和视频。现有的多模态讽刺检测方法要么简单地将多模态的特征连接起来，要么以设计的方式融合多模态信息。然而，他们忽略了讽刺话语中的不协调性，这种不协调性通常表现在模态之间或模态内部。受此启发，我们提出了一个<strong>基于BERT架构</strong>的模型，该模型专注于多模态讽刺检测的<strong>模态内部和模态间不协调</strong>。具体来说，我们受到<strong>自我注意力机制</strong>的启发，并设计了模态间注意力来捕捉模态间的不协调。此外，还应用了共同注意力机制来模拟文本中的矛盾。然后使用不协调信息进行预测。实验结果表明，我们的模型在公共多模态讽刺检测数据集上实现了最先进的性能。</p>
<p>Att-BERT 整体框架：</p>
<div align=center>
<img src="/../images/MSDtasks/AttBERT_2020.jpg" width="85%" height="85%" />
</div>

<h2 id="InCrossMGs-Liang-et-al-2021"><a href="#InCrossMGs-Liang-et-al-2021" class="headerlink" title="InCrossMGs [Liang et al. 2021]"></a>InCrossMGs [<a href="#liang2021incrossmgs">Liang <em>et al</em>. 2021</a>]</h2><p>论文下载: <a href="https://dl.acm.org/doi/abs/10.1145/3474085.3475190">Multi-Modal Sarcasm Detection with Interactive In-Modal and Cross-Modal Graphs</a><br>标题：使用交互式模态内和跨模态图进行多模态讽刺检测<br>作者：Bin Liang（哈尔滨工业大学）, Chenwei Lou, Xiang Li, Lin Gui, Min Yang, Ruifeng Xu<br>发表地点：MM 2021</p>
<p>摘要：<br>讽刺是一种奇特的形式和复杂的语言行为，用于表达某人隐含的情感表达的不协调性，这在社交媒体平台上是一种普遍现象。与纯粹基于文本的讽刺检测相比，多模态讽刺检测更适合快速增长的社交媒体平台，人们有兴趣创建多模态信息。在关注 Twitter 上由文本和图像组成的推文的多模态讽刺检测时，提高多模态讽刺检测性能的重要线索演变为如何确定文本和图像之间的不协调关系。本文从<strong>新的角度</strong>研究了多模态讽刺检测，通过为每个多模态样本构建<strong>异构模态和跨模态图（InCrossMGs）</strong>，确定特定模态内和不同模态之间的情感不一致。在此基础上，我们探索了一种<strong>交互式图卷积网络（GCN）</strong>结构，以共同和交互的方式学习模态内图和跨模态图的不协调关系，以确定讽刺检测中的重要线索。实验结果表明，所提模型在多模态讽刺检测中取得了较好的性能。</p>
<p>InCrossMGs 整体框架：</p>
<div align=center>
<img src="/../images/MSDtasks/InCrossMGs_2021.jpg" width="85%" height="85%" />
</div>


<h2 id="CMGCN-Liang-et-al-2022"><a href="#CMGCN-Liang-et-al-2022" class="headerlink" title="CMGCN [Liang et al. 2022]"></a>CMGCN [<a href="#liang2022cmgcn">Liang <em>et al</em>. 2022</a>]</h2><p>论文下载: <a href="https://aclanthology.org/2022.acl-long.124/">Multi-Modal Sarcasm Detection via Cross-Modal Graph Convolutional Network</a><br>标题：基于跨模态图卷积网络的多模态讽刺检测<br>作者：Bin Liang（哈尔滨工业大学）, Chenwei Lou, Xiang Li, Min Yang, Lin Gui, Yulan He, Wenjie Pei, Ruifeng Xu<br>发表地点：ACL 2022</p>
<p>摘要：<br>随着在线发布多模态信息的日益普及，最近已经开展了许多利用文本和视觉信息进行多模态讽刺检测的研究。在本文中，我们通过为每个实例构建一个<strong>跨模态图</strong>来明确地绘制文本和视觉模态之间的反讽关系，从新的角度研究了多模态讽刺检测。具体来说，我们首先检测与图像模态描述配对的对象，从而能够学习重要的视觉信息。然后，以对象的描述为桥梁，确定图像模态的对象与文本模态的上下文词之间关联的重要性，从而为每个多模态实例构建跨模态图。此外，我们设计了一个<strong>跨模态图卷积网络</strong>来理解多模态讽刺检测模态之间的不协调关系。大量的实验结果和深入分析表明，该模型在多模态讽刺检测方面取得了最先进的性能。</p>
<p>CMGCN 整体框架：</p>
<div align=center>
<img src="/../images/MSDtasks/CMGCN_2022.jpg" width="85%" height="85%" />
</div>


<h2 id="HKE-Liu-et-al-2022"><a href="#HKE-Liu-et-al-2022" class="headerlink" title="HKE [Liu et al. 2022]"></a>HKE [<a href="#liu2022hke">Liu <em>et al</em>. 2022</a>]</h2><p>论文下载: <a href="https://aclanthology.org/2022.emnlp-main.333/">Towards Multi-Modal Sarcasm Detection via Hierarchical Congruity Modeling with Knowledge Enhancement</a><br>标题：基于知识增强的层次一致性建模的多模态讽刺检测<br>作者：Hui Liu（香港城市大学）, Wenya Wang, Haoliang Li<br>发表地点：EMNLP 2022</p>
<p>摘要：<br>讽刺是一种语言现象，表明字面意思和隐含意图之间存在差异。由于其复杂的性质，通常很难从文本本身中检测到它。因此，多模态讽刺检测在学术界和工业界都受到了越来越多的关注。然而，大多数现有技术只模拟了文本输入与其伴随图像之间的原子级不一致，而忽略了两种模式的更复杂的组合。此外，他们忽略了<strong>外部知识</strong>中包含的丰富信息，例如图像标题。在本文中，我们通过探索基于多头交叉注意力的<strong>原子级一致性</strong>和基于图神经网络的<strong>组合级一致性</strong>，提出了一种新的讽刺检测层次框架，其中低一致性的帖子可以被识别为讽刺。此外，我们利用各种知识资源的效果进行讽刺检测。基于 Twitter 的公共多模态讽刺检测数据集的评估结果验证了所提模型的优越性。</p>
<p>HKE 整体框架：</p>
<div align=center>
<img src="/../images/MSDtasks/HKE_2022.jpg" width="85%" height="85%" />
</div>


<h2 id="MILNet-Qiao-et-al-2023"><a href="#MILNet-Qiao-et-al-2023" class="headerlink" title="MILNet [Qiao et al. 2023]"></a>MILNet [<a href="#qiao2023milnet">Qiao <em>et al</em>. 2023</a>]</h2><p>论文下载: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26138">Mutual-Enhanced Incongruity Learning Network for Multi-Modal Sarcasm Detection</a><br>标题：面向多模态讽刺检测的相互增强不协调学习网络<br>作者：Yang Qiao（山东大学）, Liqiang Jing, Xuemeng Song, Xiaolin Chen, Lei Zhu, Liqiang Nie<br>发表地点：AAAI 2023</p>
<p>摘要：<br>讽刺是一种复杂的语言现象，在当今的社交媒体平台上很普遍。多模态讽刺检测旨在识别具有多模态信息（即文本和图像）的给定样本是否具有讽刺意味。这项任务的关键在于在同一上下文中捕捉模态间和模态内的不协调。尽管现有方法取得了令人信服的成功，但它们受到从整个图像和文本中提取的不相关信息的干扰，或者由于输入不完整而忽略了一些重要信息。为了解决这些局限性，我们提出了一种用于多模态讽刺检测的相互增强不协调学习网络，名为 MILNet。特别是，我们设计了一个<strong>局部语义引导的不协调学习模块</strong>和一个<strong>全局不协调学习模块</strong>。此外，我们还引入了一个相互增强模块，以利用两个模块之间的底层一致性来提升性能。在广泛使用的数据集上进行的大量实验证明了我们的模型优于尖端方法。</p>
<p>MILNet 整体框架：</p>
<div align=center>
<img src="/../images/MSDtasks/MILNet_2023.jpg" width="85%" height="85%" />
</div>

<h2 id="DIP-Wen-et-al-2023"><a href="#DIP-Wen-et-al-2023" class="headerlink" title="DIP [Wen et al. 2023]"></a>DIP [<a href="#wen2023dip">Wen <em>et al</em>. 2023</a>]</h2><p>论文下载: <a href="https://ieeexplore.ieee.org/document/10205020">DIP: Dual Incongruity Perceiving Network for Sarcasm Detection</a><br>标题：DIP：用于讽刺检测的双重不协调感知网络<br>作者：Changsong Wen（南开大学）, Guoli Jia, Jufeng Yang<br>发表地点：CVPR 2023</p>
<p>摘要：<br>讽刺表明字面意思与真实态度相反。考虑到图文数据的普及性和互补性，我们研究了多模态讽刺检测的任务。与其他多模态任务不同，对于讽刺数据，一对图像和文本之间存在内在的不协调性，正如心理学理论所证明的那样。为了解决这个问题，我们提出了一个由两个分支组成的双重不协调感知（DIP）网络，从事实和情感层面挖掘讽刺信息。在事实方面，我们引入了一种通道重加权策略来获得语义判别嵌入，并利用高斯分布对不协调引起的不确定相关性进行建模。该分布由存储在存储库中的最新数据生成，可以自适应地模拟讽刺和非讽刺数据之间的语义相似性差异。在情感方面，我们利用具有共享参数的连体层来学习跨模态情感信息。此外，我们使用极性值来构建小批量的关系图，形成连续的对比损失以获得情感嵌入。大量的实验表明，我们提出的方法与最先进的方法相比具有良好的性能。我们的代码在 <a href="https://github.com/downdric/MSD">https://github.com/downdric/MSD</a> 上发布。</p>
<p>DIP 整体框架：</p>
<div align=center>
<img src="/../images/MSDtasks/DIP_2023.jpg" width="85%" height="85%" />
</div>

<h2 id="模型结果对比："><a href="#模型结果对比：" class="headerlink" title="模型结果对比："></a>模型结果对比：</h2><div align=center>
<img src="/../images/MSDtasks/dataset_result.jpg" width="95%" height="95%" />
</div>

<h2 id="参考文献："><a href="#参考文献：" class="headerlink" title="参考文献："></a>参考文献：</h2><p><span id="cai2019hfm">[Cai <em>et al</em>., 2019]</span> Yitao Cai, Huiyu Cai, and Xiaojun Wan. Multi-modal sarcasm detection in twitter with hierarchical fusion model. In Proceedings of the 57th Conference of the Association for Computational Linguistics, pages 2506–2515, 2019.</p>
<p><span id="xu2020drnet">[Xu <em>et al</em>., 2020]</span> Nan Xu, Zhixiong Zeng, and Wenji Mao. Reasoning with multimodal sarcastic tweets via modeling cross-modality contrast and semantic association. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 3777–3786, 2020.</p>
<p><span id="#pan2020attbert">[Pan <em>et al</em>., 2020]</span> Hongliang Pan, Zheng Lin, Peng Fu, Yatao Qi, and Weiping Wang. Modeling intra and inter-modality incongruity for multi-modal sarcasm detection. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1383–1392, 2020.</p>
<p><span id="liang2021incrossmgs">[Liang <em>et al</em>., 2021]</span> Bin Liang, Chenwei Lou, Xiang Li, Lin Gui, Min Yang, and Ruifeng Xu. Multi-modal sarcasm detection with interactive in-modal and cross-modal graphs. In Proceedings of the 29th ACM International Conference on Multimedia, pages 4707–4715, 2021.</p>
<p><span id="liang2022cmgcn">[Liang <em>et al</em>., 2022]</span> Bin Liang, Chenwei Lou, Xiang Li, Min Yang, Lin Gui, Yulan He, Wenjie Pei, and Ruifeng Xu. Multi-modal sarcasm detection via cross-modal graph convolutional network. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), volume 1, pages 1767–1777. Association for Computational Linguistics, 2022.</p>
<p><span id="liu2022hke">[Liu <em>et al</em>., 2022]</span> Hui Liu, Wenya Wang, and Haoliang Li. Towards multi-modal sarcasm detection via hierarchical congruity modeling with knowledge enhancement. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP 2022), pages 4995–5006. Association for Computational Linguistics, 2022.</p>
<p><span id="qiao2023milnet">[Qiao <em>et al</em>., 2023]</span> Yang Qiao, Liqiang Jing, Xuemeng Song, Xiaolin Chen, Lei Zhu, and Liqiang Nie. Mutual-enhanced incongruity learning network for multi-modal sarcasm detection. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 9507–9515, 2023.</p>
<p><span id="wen2023dip">[Wen <em>et al</em>., 2023]</span> Changsong Wen, Guoli Jia, and Jufeng Yang. Dip: Dual incongruity perceiving network for sarcasm detection. In Proceedings of the IEEE&#x2F;CVF Conference on Computer Vision and Pattern Recognition, pages 2540–2550, 2023. </p>
]]></content>
      <categories>
        <category>【阅读笔记】</category>
      </categories>
      <tags>
        <tag>MultiModal</tag>
        <tag>Sarcasm Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>【论文分享】嘲讽检测综述</title>
    <url>/2023/07/07/SDtasks_survey/</url>
    <content><![CDATA[<h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>论文下载：<a href="https://arxiv.org/abs/2202.02516">A SURVEY ON AUTOMATED SARCASM DETECTION ON TWITTER</a><br>标题：基于 Twitter 的嘲讽检测论文调查<br>作者：Bleau Moores, Vijay Mago<br>发表地点：A PREPRINT in Arxiv（预印版）</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>自动嘲讽检测是计算机科学中一个不断发展的领域。短文信息越来越多地被用于交流，尤其是在 Twitter 等社交媒体平台上。由于语境不足或缺失，这些信息中未识别的嘲讽会颠倒语句的含义，导致混乱和交流失败。本文介绍了当前用于嘲讽检测的各种方法，包括通过上下文、发帖历史和机器学习模型进行检测。此外，还可以观察到向深度学习方法的转变，这可能是由于使用具有诱导特征而非离散特征的模型与变压器的创新相结合所带来的好处。</p>
]]></content>
      <categories>
        <category>【论文分享】</category>
      </categories>
      <tags>
        <tag>Sarcasm Detection</tag>
      </tags>
  </entry>
  <entry>
    <title>联系我</title>
    <url>/2022/10/14/newpage/</url>
    <content><![CDATA[<p>欢迎来到我的第一条blog！<br>Welcome to my first blog!</p>
<h2 id="你可以这样联系我"><a href="#你可以这样联系我" class="headerlink" title="你可以这样联系我"></a>你可以这样联系我</h2><p>E-Mail：<a href="mailto:&#115;&#99;&#110;&#x75;&#95;&#119;&#113;&#102;&#x40;&#109;&#x2e;&#115;&#x63;&#110;&#x75;&#x2e;&#x65;&#100;&#117;&#x2e;&#99;&#110;">&#115;&#99;&#110;&#x75;&#95;&#119;&#113;&#102;&#x40;&#109;&#x2e;&#115;&#x63;&#110;&#x75;&#x2e;&#x65;&#100;&#117;&#x2e;&#99;&#110;</a><br>CSDN: <a href="https://blog.csdn.net/Jorffy?type=blog">https://blog.csdn.net/Jorffy?type=blog</a></p>
]]></content>
  </entry>
  <entry>
    <title>【论文分享】基于可学习图增强的邻居监督图对比学习</title>
    <url>/2023/09/08/NCLA/</url>
    <content><![CDATA[<h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>论文下载：<a href="https://ojs.aaai.org/index.php/AAAI/article/view/26168">Neighbor Contrastive Learning on Learnable Graph Augmentation</a><br>标题：基于可学习图增强的邻居监督图对比学习<br>作者：Xiao Shen（海南大学）, Dewang Sun, Shirui Pan, Xi Zhou, Laurence T. Yang<br>发表地点：AAAI 2023<br>代码开源：<a href="https://github.com/shenxiaocam/NCLA">https://github.com/shenxiaocam/NCLA</a></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>近年来，旨在从未标记的图中学习表示的图对比学习（GCL）取得了长足的进步。然而，现有的GCL方法大多采用人工设计的图增强，对各种图数据集都很敏感。此外，最初在计算机视觉中产生的对比损失已直接应用于图形数据，其中相邻节点被视为负值，因此与锚点相距很远。然而，这与网络的同质假设相矛盾，即连接的节点通常属于同一类，并且应该彼此靠近。在这项工作中，我们提出了一种名为NCLA的端到端自动GCL方法，用于将邻居对比学习应用于可学习图增强。多头图注意力机制自动学习多个自适应拓扑图增强视图，无需先验领域知识即可兼容各种图数据集。此外，通过将网络拓扑作为监督信号，设计了邻域对比损失，以允许每个锚点具有多个正信号。在拟议的 NCLA 中，增强和嵌入都是端到端学习的。在基准数据集上的大量实验表明，当标签极其有限时，NCLA在自监督GCL上产生了最先进的节点分类性能，甚至超过了监督节点。我们的代码在 <a href="https://github.com/shenxiaocam/NCLA">https://github.com/shenxiaocam/NCLA</a> 上发布。</p>
<span id="more"></span>

<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在过去几年中，图神经网络（GNN）因其在节点分类（Kipf 和 Welling，2017 年）、链接预测（Shen 和 Chung，2020 年）和图分类等各种图挖掘任务中的出色表现而备受关注（Hamilton, Ying 和 Leskovec 2017）。现有的大多数 GNN 都是以监督的方式进行训练的，这在很大程度上依赖于大量注释良好的标签。然而，在现实世界的应用中，收集大量带标签的图结构数据往往需要耗费大量资源和时间（Shen 等人，2020a；Shen 等人，2020b；Shen、Mao 和 Chung，2020；Wu 等人，2020；Dai 等人，2022）。</p>
<p>对比学习（Contrastive Learning，CL）是最具代表性的自监督学习技术之一，可以减少对人工标签的依赖。对比学习在计算机视觉（CV）（Zhu 等人，2020 年）和自然语言处理（NLP）（Aberdam 等人，2021 年）的无监督表示学习中表现出了前所未有的性能。最近，在图对比学习（GCL）（Hassani 和 Khasahmadi，2020 年；Zhu 等人，2020 年；Xia 等人，2022a；Xia 等人，2022b；Zheng 等人，2022 年）的发展启发下，人们投入了巨大的努力，将 GNN 与 CL 结合起来，从无标签图中学习稳健的表示。</p>
<p>现有的 GCL 方法大多采用类似的模式。首先，它们采用各种图增强策略，如节点丢弃（You 等人，2020 年）、边扰动（Zhu 等人，2020 年）、属性掩蔽（Zhu 等人，2021 年）、子图（Yang 等人，2022 年）和图扩散（Hassani 和 Khasahmadi，2020 年），生成多个具有差异的图增强视图。其次，他们应用了 CV 中广泛使用的对比损失，如 InfoNCE（Van den Oord、Li 和 Vinyals，2018 年）、归一化温度标度交叉熵（NT-Xent）（Zhu et al. 2020）、Jensen-Shannon Divergence（JSD）（Nowozin、Cseke 和 Tomioka，2016）和 Triplet loss（Schroff、Kalenichenko 和 Philbin，2015）等，根据 InfoMax（Linsker，1988）原理提取不同增强视图之间的共同核心信息。尽管 GCL 得到了蓬勃发展，但标准范式在图增强和对比目标方面仍存在一些缺陷。</p>
<p>CL的理论和实证分析表明，好的增强视图应该是多样化的，同时保持与任务相关的信息完好无损（Tian等人，2020）。然而，现有的手工图增强策略会随机扰动图拓扑结构，无法保持任务相关信息的完整性。例如，丢弃一条重要的边会严重破坏与下游任务高度相关的图拓扑结构，从而导致图嵌入质量低下（Zhu 等，2021）。此外，由于图数据的多样性，目前还没有适用于不同数据集的通用图增强技术（You 等人，2020 年；You 等人，2021 年）。因此，现有的临时图增强方法必须根据先前的领域知识或反复试验为每个图数据集手动选择（You 等人，2020 年），这大大限制了现有 GCL 方法的效率和普遍适用性。</p>
<div align=center>
<img src="/../images/NCLA/Fig1_3cl.jpg" width="95%" height="95%" />
</div>

<p>另一方面，现有的 GCL 方法直接将最初在 CV 中提出的对比损失应用于图形数据（Qiu 等人，2020 年；You 等人，2020 年；Zhu 等人，2020 年；Wan 等人，2021a；Wan 等人，2021b；Zhu 等人，2021 年），而不注意图像与图形之间的内在区别。对比损失被用来指导表征学习，将正对图像拉到一起，将负对图像推开。如图 1(a)和 1(b)所示，在 InfoNCE 和 NT-Xent 中，通过创建同一节点的不同增强视图，每个锚点都会形成一对正对。然后，InfoNCE 将来自不同视图的所有其他不同节点视为负节点。而 NTXent 则引入了更多的否定，将一个视图内和来自不同视图的所有不同节点都视为否定。值得注意的是，在 InfoNCE 和 NT-Xent 中，相邻节点都被视为负节点，然后被推离锚点。然而，在 GCL 中，与 CL 相结合的 GNN 通常基于同类假设，即相连节点通常属于同一类别（McPherson、Smith-Lovin 和 Cook，2001 年）。换句话说，连接的节点应该彼此相似，而不是相距甚远。由于图像和图形之间的内在区别，直接将 CV 中开发的对比损失应用于 GCL 会忽略网络拓扑结构，导致嵌入结果与 GNN 的同类假设相矛盾。</p>
<p>为了弥补上述局限，我们在这项工作中提出了一种新的 GCL 方法，命名为 NCLA，它将邻接对比学习应用于可学习图增强。一方面，NCLA 采用多头图注意网络（GAT）（Veličković 等人，2018 年）生成具有自适应拓扑的 K 个可学习图增强视图。这种可学习的增强可以自动兼容各种图数据集，而无需事先了解领域知识。此外，与可能严重破坏原始拓扑的不恰当手工图增强相比，NCLA 生成的基于注意力的可学习增强视图将保留与原始图完全相同的节点和边，但具有不同的自适应边权重。此外，现有的 GCL 方法对不同的增强视图使用完全相同的 GNN 编码器和绑定的可学习参数（You 等人，2020 年；Zhu 等人，2020 年；Zhu 等人，2021 年），而在 NCLA 中，每个增强视图都有自己的可学习参数。因此，NCLA 可以生成更安全的图增强，而无需对原始拓扑进行不当修改，同时还能保证不同增强视图之间的多样性。另一方面，与之前直接利用最初在 CV 中提出的对比损失（如 InfoNCE 或 NT-Xent）的 GCL 方法不同，我们为节点-节点 GCL 设计了一种新的邻居对比损失。所提出的邻居对比损失是对 NT-Xent 损失（Zhu 等人，2020 年）的新扩展，它将网络拓扑作为监督信号来定义 GCL 中的正负。具体地说，与 NT-Xent 中每个锚点只能形成一对正值不同，所提出的邻居对比损失允许每个锚点有多个正值。如图 1(c)所示，这些多个正对来自不同视图中的同一节点，以及锚点在同一视图中的邻居和来自不同视图的邻居。因此，视图内和不同视图中锚点的非邻居将被视为视图内和视图间的阴性。这项工作的贡献可总结如下：</p>
<ul>
<li>与大多数现有的 GCL 方法必须根据数据集手动挑选手工图增强相比，所提出的 NCLA 首次采用了多头图注意力机制作为可学习的图增强函数，其中每个头对应一个增强视图。这种基于注意力的可学习图增强避免了对原始拓扑结构的不当修改，并能自动兼容各种图数据集。</li>
<li>现有的 GCL 方法直接将 CV 中的对比损失应用于图形数据，忽略了网络拓扑结构。CV 中的损失来处理图数据，而忽略了网络拓扑结构。据我们所知，我们的工作是 在节点-节点 GCL 中研究邻接对比学习的开创性尝试之一。通过将网络拓扑结构作为监督信号，允许每个锚点出现多个阳性结果。</li>
<li>在标准的 GCL 范式中，图增强和嵌入学习分两个阶段进行，可能需要进行双层优化。相比之下，在 NCLA 中，图形增强与嵌入学习是端到端的，因此具有很高的灵活性和易用性。</li>
<li>在各种图数据集上进行的大量实验表明，NCLA 在使用稀缺标签进行半监督节点分类时，始终优于最先进的 GCL 方法，甚至优于某些监督 GNN。</li>
</ul>
<h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><div align=center>
<img src="/../images/NCLA/Fig2_model.jpg" width="95%" height="95%" />
</div>]]></content>
      <categories>
        <category>【论文分享】</category>
      </categories>
      <tags>
        <tag>Contrastive Learning</tag>
        <tag>Graph</tag>
      </tags>
  </entry>
</search>
